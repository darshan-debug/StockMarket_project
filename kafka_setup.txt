downloaded kafka binary, and unziped it, to location: C:\kafka\kafka_2.13-3.9.1\
generated cluster id:
C:\kafka\kafka_2.13-3.9.1\bin\windows>       .\kafka-storage.bat random-uuid
4n2aTYG0Tn-ike55mt7i3Q
then executed this command:
cd C:\kafka\kafka_2.13-3.9.1\
.\bin\windows\kafka-storage.bat format --standalone -t 4n2aTYG0Tn-ike55mt7i3Q -c config\kraft\server.properties

start the kafka server(broker) using this command:
cd C:\kafka\kafka_2.13-3.9.1\
.\bin\windows\kafka-server-start.bat config\kraft\server.properties


cd C:\kafka\kafka_2.13-3.9.1\
other commands:

//connector automatically creates topic
.\bin\windows\kafka-topics.bat --create --topic quickstart-events.stockmarket.transactions --bootstrap-server localhost:9092 --config retention.ms=3600000

.\bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092
.\bin\windows\kafka-consumer-groups.bat --bootstrap-server localhost:9092 --list

.\bin\windows\kafka-topics.bat --describe --topic quickstart-events --bootstrap-server localhost:9092

.\bin\windows\kafka-console-producer.bat --topic quickstart-events --bootstrap-server localhost:9092

.\bin\windows\kafka-consumer-groups.bat --bootstrap-server localhost:9092 --describe --group file_writer_consumer_group_CG1

.\bin\windows\kafka-console-consumer.bat --topic quickstart-events.stockmarket.transactions --from-beginning --bootstrap-server localhost:9092
.\bin\windows\kafka-console-consumer.bat --topic quickstart-events.stockmarket.transactions --bootstrap-server localhost:9092 --group my-shared-group1 --from-beginning

.\bin\windows\kafka-topics.bat --delete --topic quickstart-events --bootstrap-server localhost:9092

temp log dir( kafka topic data is stored here, delete this dir, to cleanup any topic data): C:\tmp\kraft-combined-logs
in case of failure, server logs can be found at: C:\kafka\kafka_2.13-3.9.1\logs

command to trigger kafka connect worker:
download jar from: https://repo1.maven.org/maven2/org/mongodb/kafka/mongo-kafka-connect/1.16.0/   , 
https://repo1.maven.org/maven2/org/apache/avro/avro/1.11.3/
cd C:\kafka\kafka_2.13-3.9.1\
.\bin\windows\connect-standalone.bat config\connect-standalone.properties connector_config\MongoSourceConnector.json

The MongoDB Kafka Connector (specifically, the Source Connector) is designed to stream data changes from a MongoDB replica set or sharded cluster into Kafka topics in real-time. It leverages MongoDB's Change Streams feature.